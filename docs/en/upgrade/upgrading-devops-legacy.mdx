---
weight: 30
sourceSHA: 03b11615a739095db87029e6b3ad9b9986a42c6033f4d265744147def3832b5a
---

# Upgrading DevOps Legacy

:::warning
This section contains a temporary case and will be updated to a formal upgrade process later.
:::

This section describes the specific steps to upgrade the `global` cluster.

Before starting the upgrade, please ensure that prerequisite checks, package downloads and verifications, and node preprocessing have been completed.

## Process

<Steps>
  ### Upload and Extract Installation Package

  Upload the installation package to any machine of the `global` cluster control node and extract the installation package using the following command:

  ```shell
  # Assume the /root/cpaas-install folder already exists on the machine
  tar -xvf {installation_package_path}/{installation_package_name} -C /root/cpaas-install
  cd /root/cpaas-install/installer || exit 1
  ```

  <Directive type="info" title="INFO">
    - This machine will become the first control node after the installation of the `global` cluster is completed.
    - The extracted installation package requires at least **100GB** of disk space; please ensure sufficient storage resources.
  </Directive>

  ### Start Installer

  Execute the following installation script to start the installer. Upon successful startup of the installer, the command line terminal will output the UI access address.

  After about 5 minutes, you can access the Web UI provided by the installer using a browser on your PC.

  ```bash
  bash setup.sh
  ```

  The installer uses Kube-OVN network plugin by default. If you want to use Calico network plugin, please execute:

  ```bash
  bash setup.sh --network-mode calico
  ```

  <Directive type="note" title="Other Parameters">
    - To access using IPv6 addresses: append the `--ip-family ipv6` parameter.
    - To support both IPv4 and IPv6: append the `--ip-family dual` parameter.
  </Directive>

  <Directive type="warning" title="Note">
    Ensure that the IP address of the node where the installer is located and the 8080 port are accessible, so that the Web UI provided by the installer can be accessed successfully after it has started.
  </Directive>

  ### Parameter Configuration

  Complete the installation parameter configuration following the page guidance, and then confirm the installation.

  Detailed descriptions of key parameters can be found in [Parameter Description](#parameters); please read carefully and configure according to actual needs.

  ### Verify Installation Success

  After installation is complete, the page will display the platform access address. Clicking the **Access** button will redirect you to the platform Web UI.

  In the **Platform Management** view, click **Cluster Management > Clusters**, and locate the cluster named `global`.

  Use the drop-down menu on the right to select `CLI Tool`, and execute the following commands to verify the installation status:

  ```shell
  # Check if there are any failed Charts
  kubectl get apprelease --all-namespaces
  # Check if there are any failed Pods
  kubectl get pod --all-namespaces | awk '{if ($4 != "Running" && $4 != "Completed")print}' | awk -F'[/ ]+' '{if ($3 != $4)print}'
  ```
</Steps>

## Parameter Description {#parameters}

<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Parameter</th>
    <th style={{ whiteSpace: 'nowrap' }}>Description</th>
  </tr>

  <tr>
    <td><b>Kubernetes Version</b></td>

    <td>
      Optional versions have been rigorously tested to ensure stability and compatibility. <br />
      <b>Recommendation:</b> Choose the latest version for the best features and support.
    </td>
  </tr>

  <tr>
    <td><b>Network Protocol of the Cluster</b></td>

    <td>
      Supports three modes: IPv4 single stack, IPv6 single stack, and IPv4/IPv6 dual stack. <br />
      <b>Note:</b> If you choose dual stack mode, please ensure that all nodes have correctly configured IPv6 addresses; the network protocol cannot be changed once set.
    </td>
  </tr>

  <tr>
    <td><b>Cluster Address</b></td>

    <td>
      <ul>
        Input the pre-prepared domain name. If there is no domain name, input the pre-prepared <code>global VIP</code>. <br />
        <code>Self-built VIP</code> is turned off by default and only needs to be enabled if you do not provide a LoadBalancer. Once enabled, the installer will automatically deploy <code>keepalived</code> to provide soft load support. <br />
        <b>Note:</b> When using <code>Self-built VIP</code>, the following conditions must be met, <br />

        - There is an available VRID; <br />
        - Host network supports VRRP protocol; <br />
        - All control nodes and the VIP must be in the same subnet. <br />
      </ul>

      <ul>
        <b>Tip:</b> For the <b>single-node deployment</b> in the functional experience scenario, you can directly input the node IP. There is no need to enable <code>Self-built VIP</code> or prepare network resources such as <code>global VIP</code>.
      </ul>
    </td>
  </tr>

  <tr>
    <td><b>Platform Access Address</b></td>

    <td>
      <ul>
        If you do not need to differentiate between <b>Cluster Address</b> and <b>Platform Access Address</b>, enter the same address as <b>Cluster Address</b>. <br />
        If you need to differentiate, for example the global cluster is for internal access only and the platform needs to provide external access, input the pre-prepared domain name or <code>External IP</code>. <br />
        The platform defaults to using HTTPS access and does not enable HTTP. If HTTP access needs to be enabled, please enable it in <b>Advanced Settings</b> (not recommended). <br />
        <b>Note:</b> The following situations must input a domain name, <br />

        - Plans to implement a disaster recovery solution for the global cluster; <br />
        - The platform needs to support IPv6 access. <br />
      </ul>

      <ul>
        <b>Tip:</b> If you need to configure more platform access addresses, you can add them in the next step under <b>Other Settings > Other Access Addresses for the Platform</b>, or refer to the user manual to add them in platform management after installation is complete. <br />
      </ul>
    </td>
  </tr>

  <tr>
    <td><b>Certificate</b></td>

    <td>
      The platform defaults to providing self-signed certificates to support HTTPS access. <br />
      If you need to use a custom certificate, you can upload an existing certificate.
    </td>
  </tr>

  <tr>
    <td><b>Image Repository</b></td>

    <td>
      The default uses the <code>Platform Deployment</code> image repository, which contains images for all components. <br />
      If you need to use <code>External</code> image repository, please contact technical support for the image synchronization plan and proceed with the configuration afterwards.
    </td>
  </tr>

  <tr>
    <td><b>Container Network</b></td>

    <td>
      The default subnet of the cluster and the service subnet must not overlap. <br />
      When using Kube-OVN Overlay network, ensure that the container network and host network are not in the same subnet, or it may cause network anomalies.
    </td>
  </tr>

  <tr>
    <td><b>Node Name</b></td>

    <td>
      If you choose <code>Use Host Name as Node Name</code>, please ensure that all nodes have unique host names.
    </td>
  </tr>

  <tr>
    <td><b>Isolation of Nodes in Global Cluster Platform</b></td>

    <td>
      Enable only if you plan to run application workloads in the `global` cluster. <br />
      <b>Once enabled:</b><br />

      - Nodes can be set to <code>Platform Exclusive</code>, meaning they only run platform components, ensuring isolation between the platform and application workloads; <br />
      - DaemonSet type workloads are excluded.
    </td>
  </tr>

  <tr>
    <td><b>Add Node</b></td>

    <td>
      <b>Control Nodes:</b>

      <ul>
        - Support adding 1 or 3 control nodes (3 for high availability configuration); <br />
        - If <code>Platform Exclusive</code> is enabled, <code>Deployable Applications</code> will be forcibly turned off; control nodes will only run platform components; <br />
        - If <code>Platform Exclusive</code> is turned off, you can choose whether to enable <code>Deployable Applications</code>, allowing control nodes to run application workloads. <br />
      </ul>

      <b>Compute Nodes:</b>

      <ul>
        - If <code>Platform Exclusive</code> is enabled, <code>Deployable Applications</code> will be forcibly turned off; <br />
        - If <code>Platform Exclusive</code> is turned off, <code>Deployable Applications</code> will be forcibly enabled. <br />
      </ul>

      <p>When using Kube-OVN, you can specify the node network card by entering the gateway name.</p>
      <p>If the node availability check fails, please adjust according to the page prompts and re-add.</p>
    </td>
  </tr>
</table>

## Installer Cleanup

Typically, the installer will be automatically deleted after the installation is complete. If the installer has not been automatically deleted over 30 minutes after the installation is complete, please execute the following command on the node where the installer is located to forcibly delete the installer container:

```bash
docker rm -f minialauda-control-plane
```
